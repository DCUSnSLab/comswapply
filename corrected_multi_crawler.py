import requests
from bs4 import BeautifulSoup
import sqlite3
import time
import re
import uuid
from datetime import datetime
from typing import List, Dict, Tuple, Optional

class CorrectedMultiUniversityCrawler:
    def __init__(self, db_path='competition_ratio_enhanced.db'):
        self.db_path = db_path
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        # ìˆ˜ì •ëœ ëŒ€í•™êµë³„ í¬ë¡¤ë§ ì„¤ì •
        self.university_configs = {
            'CKU': {  # ëŒ€êµ¬ê°€í†¨ë¦­ëŒ€í•™êµ (ìˆ˜ì •ë¨)
                'name': 'ëŒ€êµ¬ê°€í†¨ë¦­ëŒ€í•™êµ',
                'url': 'https://addon.jinhakapply.com/RatioV1/RatioH/Ratio10460911.html',
                'parser': self.parse_dcu_jinhakapply,
                'target_college': 'ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©ëŒ€í•™',
                'target_departments': ['ì»´í“¨í„°ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€', 'AIë¹…ë°ì´í„°ê³µí•™ê³¼', 'ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©í•™ê³¼']
            },
            'DGU': {  # ëŒ€êµ¬ëŒ€í•™êµ
                'name': 'ëŒ€êµ¬ëŒ€í•™êµ',
                'url': 'https://addon.jinhakapply.com/RatioV1/RatioH/Ratio10440731.html',
                'parser': self.parse_dgu_jinhakapply,
                'target_college': 'ITÂ·ê³µê³¼ëŒ€í•™',
                'target_departments': ['ì»´í“¨í„°ì •ë³´ê³µí•™ë¶€']
            },
            'YNU': {  # ì˜ë‚¨ëŒ€í•™êµ
                'name': 'ì˜ë‚¨ëŒ€í•™êµ',
                'url': 'https://ratio.uwayapply.com/Sl5KOmJKZiUmOiZKLWZUZg==',
                'parser': self.parse_uwayapply,
                'target_college': 'ë””ì§€í„¸ìœµí•©ëŒ€í•™',
                'target_departments': []  # ì „ì²´ í•™ê³¼ ìˆ˜ì§‘
            },
            'KMU': {  # ê³„ëª…ëŒ€í•™êµ
                'name': 'ê³„ëª…ëŒ€í•™êµ',
                'url': 'https://ratio.uwayapply.com/Sl5KOk05SmYlJjomSi1mVGY=',
                'parser': self.parse_uwayapply,
                'target_college': None,  # ë‹¨ê³¼ëŒ€í•™ ìƒê´€ì—†ì´
                'target_departments': ['ì»´í“¨í„°ê³µí•™ê³¼', 'ê²Œì„ì†Œí”„íŠ¸ì›¨ì–´', 'ëª¨ë¹Œë¦¬í‹°ì†Œí”„íŠ¸ì›¨ì–´']
            }
        }
    
    def fetch_page(self, url: str) -> Optional[str]:
        """ì›¹í˜ì´ì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            response = self.session.get(url, timeout=30)
            response.encoding = 'utf-8'
            return response.text
        except Exception as e:
            print(f"í˜ì´ì§€ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({url}): {e}")
            return None
    
    def find_admission_type_in_context(self, element):
        """ìš”ì†Œì˜ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì „í˜• íƒ€ì…ì„ ì°¾ìŠµë‹ˆë‹¤."""
        admission_patterns = {
            'í•™ìƒë¶€êµê³¼(êµê³¼ì „í˜•)': ['êµê³¼ì „í˜•'],
            'í•™ìƒë¶€êµê³¼(ì§€ì—­êµê³¼ì „í˜•)': ['ì§€ì—­êµê³¼ì „í˜•'],
            'í•™ìƒë¶€êµê³¼(ê°€í†¨ë¦­ì§€ë„ìì¶”ì²œì „í˜•)': ['ê°€í†¨ë¦­ì§€ë„ìì¶”ì²œì „í˜•'],
            'í•™ìƒë¶€êµê³¼(íŠ¹ì„±í™”ê³ ì „í˜•)': ['íŠ¹ì„±í™”ê³ ì „í˜•'],
            'í•™ìƒë¶€êµê³¼(ê¸°íšŒê· í˜•ì „í˜•)': ['ê¸°íšŒê· í˜•ì „í˜•'],
            'í•™ìƒë¶€êµê³¼(ì§€ì—­ê¸°íšŒê· í˜•ì „í˜•)': ['ì§€ì—­ê¸°íšŒê· í˜•ì „í˜•'],
            'í•™ìƒë¶€ì¢…í•©(ì¢…í•©ì „í˜•)': ['ì¢…í•©ì „í˜•'],
            'í•™ìƒë¶€ì¢…í•©(ì§€ì—­ì¢…í•©ì „í˜•)': ['ì§€ì—­ì¢…í•©ì „í˜•'],
            'í•™ìƒë¶€ì¢…í•©(SWì „í˜•)': ['SWì „í˜•'],
            'í•™ìƒë¶€êµê³¼(ë†ì–´ì´Œ)': ['ë†ì–´ì´Œ'],
            'í•™ìƒë¶€êµê³¼(ê¸°íšŒê· í˜•ì„ ë°œì „í˜•)': ['ê¸°íšŒê· í˜•ì„ ë°œì „í˜•'],
            'í•™ìƒë¶€êµê³¼(ì„±ì¸í•™ìŠµì)': ['ì„±ì¸í•™ìŠµì'],
            'í•™ìƒë¶€êµê³¼(íŠ¹ì„±í™”ê³ ì¡¸ì¬ì§ì)': ['íŠ¹ì„±í™”ê³ ì¡¸ì¬ì§ì']
        }
        
        context_text = ""
        current = element
        for _ in range(10):
            current = current.find_previous_sibling()
            if current:
                context_text += " " + current.get_text()
            else:
                break
        
        parent = element.parent
        if parent:
            context_text += " " + parent.get_text()
        
        for admission_type, patterns in admission_patterns.items():
            if any(pattern in context_text for pattern in patterns):
                return admission_type
        
        return 'ì¼ë°˜ì „í˜•'  # ê¸°ë³¸ê°’
    
    def parse_dcu_jinhakapply(self, html_content: str, university_code: str) -> List[Dict]:
        """ëŒ€êµ¬ê°€í†¨ë¦­ëŒ€í•™êµ (addon.jinhakapply.com) ì‚¬ì´íŠ¸ íŒŒì‹±"""
        soup = BeautifulSoup(html_content, 'html.parser')
        competition_data = []
        
        config = self.university_configs[university_code]
        target_college = config['target_college']
        target_departments = config['target_departments']
        
        tables = soup.find_all('table')
        print(f"{config['name']}: {len(tables)}ê°œ í…Œì´ë¸” ë°œê²¬")
        
        for table_idx, table in enumerate(tables):
            current_admission_type = self.find_admission_type_in_context(table)
            rows = table.find_all('tr')
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 5:
                    cell_texts = [cell.get_text(strip=True) for cell in cells]
                    
                    if len(cell_texts) > 0 and target_college in cell_texts[0]:
                        department_raw = cell_texts[1] if len(cell_texts) > 1 else ''
                        
                        # ëŒ€ìƒ í•™ê³¼ í™•ì¸ (í†µí•©ëª¨ì§‘ í¬í•¨)
                        is_target = (
                            any(target in department_raw for target in target_departments) or
                            'ë‹¨ê³¼ëŒ€í•™í†µí•©ëª¨ì§‘' in department_raw
                        )
                        
                        if is_target:
                            try:
                                recruitment_count = self.extract_number(cell_texts[2])
                                applicant_count = self.extract_number(cell_texts[3])
                                
                                clean_department = self.clean_department_name(department_raw, university_code)
                                
                                competition_data.append({
                                    'university_code': university_code,
                                    'college': cell_texts[0],
                                    'department': clean_department,
                                    'admission_type': current_admission_type,
                                    'recruitment_count': recruitment_count,
                                    'applicant_count': applicant_count
                                })
                                
                            except (ValueError, IndexError) as e:
                                print(f"íŒŒì‹± ì˜¤ë¥˜: {e}")
        
        return competition_data
    
    def parse_dgu_jinhakapply(self, html_content: str, university_code: str) -> List[Dict]:
        """ëŒ€êµ¬ëŒ€í•™êµ (addon.jinhakapply.com) ì‚¬ì´íŠ¸ íŒŒì‹± - íŠ¹í™”ëœ ë¡œì§"""
        soup = BeautifulSoup(html_content, 'html.parser')
        competition_data = []
        
        config = self.university_configs[university_code]
        target_college = config['target_college']  # ITÂ·ê³µê³¼ëŒ€í•™
        target_departments = config['target_departments']  # ['ì»´í“¨í„°ì •ë³´ê³µí•™ë¶€']
        target_majors = ['ì»´í“¨í„°ê³µí•™ì „ê³µ', 'ì»´í“¨í„°ì†Œí”„íŠ¸ì›¨ì–´ì „ê³µ', 'ì‚¬ì´ë²„ë³´ì•ˆì „ê³µ']
        
        tables = soup.find_all('table')
        print(f"{config['name']}: {len(tables)}ê°œ í…Œì´ë¸” ë°œê²¬")
        
        for table_idx, table in enumerate(tables):
            current_admission_type = self.find_admission_type_in_context(table)
            rows = table.find_all('tr')
            
            for row_idx, row in enumerate(rows):
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 5:
                    cell_texts = [cell.get_text(strip=True) for cell in cells]
                    
                    # ITÂ·ê³µê³¼ëŒ€í•™ í™•ì¸
                    college_name = cell_texts[0] if len(cell_texts) > 0 else ''
                    department_raw = cell_texts[1] if len(cell_texts) > 1 else ''
                    
                    # ITÂ·ê³µê³¼ëŒ€í•™ && ì»´í“¨í„°ì •ë³´ê³µí•™ë¶€ ì°¾ê¸°
                    is_target_college = target_college in college_name
                    is_target_department = any(dept in department_raw for dept in target_departments)
                    
                    # ì„¸ë¶€ ì „ê³µë“¤ë„ í™•ì¸ (ì»´í“¨í„°ê³µí•™ì „ê³µ, ì»´í“¨í„°ì†Œí”„íŠ¸ì›¨ì–´ì „ê³µ, ì‚¬ì´ë²„ë³´ì•ˆì „ê³µ)
                    is_target_major = any(major in department_raw for major in target_majors)
                    
                    if is_target_college or is_target_department or is_target_major:
                        try:
                            recruitment_count = self.extract_number(cell_texts[2])
                            applicant_count = self.extract_number(cell_texts[3])
                            
                            # ëŒ€êµ¬ëŒ€í•™êµ ì „ìš© í•™ê³¼ëª… ì •ë¦¬
                            if is_target_department and not is_target_major:
                                # ì»´í“¨í„°ì •ë³´ê³µí•™ë¶€ ìì²´
                                clean_department = department_raw
                            else:
                                # ì„¸ë¶€ ì „ê³µì´ ìˆëŠ” ê²½ìš° (ì»´í“¨í„°ì •ë³´ê³µí•™ë¶€(ì»´í“¨í„°ê³µí•™ì „ê³µ) ë“±)
                                clean_department = department_raw
                            
                            # ì •ë¦¬ëœ ì´ë¦„ ì ìš©
                            clean_department = self.clean_department_name(clean_department, university_code)
                            
                            competition_data.append({
                                'university_code': university_code,
                                'college': college_name if college_name else target_college,
                                'department': clean_department,
                                'admission_type': current_admission_type,
                                'recruitment_count': recruitment_count,
                                'applicant_count': applicant_count
                            })
                            
                            print(f"  ğŸ“Š {config['name']} ë°ì´í„° ìˆ˜ì§‘: {clean_department} | {current_admission_type} | "
                                  f"ëª¨ì§‘:{recruitment_count} ì§€ì›:{applicant_count}")
                            
                        except (ValueError, IndexError) as e:
                            print(f"  âŒ íŒŒì‹± ì˜¤ë¥˜: {e} - {cell_texts}")
        
        return competition_data
    
    def parse_uwayapply(self, html_content: str, university_code: str) -> List[Dict]:
        """ì˜ë‚¨ëŒ€, ê³„ëª…ëŒ€ (ratio.uwayapply.com) ì‚¬ì´íŠ¸ íŒŒì‹±"""
        soup = BeautifulSoup(html_content, 'html.parser')
        competition_data = []
        
        config = self.university_configs[university_code]
        target_college = config['target_college']
        target_departments = config['target_departments']
        
        tables = soup.find_all('table')
        print(f"{config['name']}: {len(tables)}ê°œ í…Œì´ë¸” ë°œê²¬")
        
        for table in tables:
            rows = table.find_all('tr')
            
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 4:
                    cell_texts = [cell.get_text(strip=True) for cell in cells]
                    
                    if len(cell_texts) >= 5:
                        college_name = cell_texts[0]
                        department_raw = cell_texts[1]
                        
                        # ëŒ€ìƒ í™•ì¸
                        is_target = False
                        if target_college:
                            is_target = target_college in college_name
                        elif target_departments:
                            is_target = any(target in department_raw for target in target_departments)
                        
                        if is_target:
                            try:
                                recruitment_count = self.extract_number(cell_texts[2])
                                applicant_count = self.extract_number(cell_texts[3])
                                
                                clean_department = self.clean_department_name(department_raw, university_code)
                                
                                competition_data.append({
                                    'university_code': university_code,
                                    'college': college_name,
                                    'department': clean_department,
                                    'admission_type': 'ì¼ë°˜ì „í˜•',  # uwayapplyëŠ” ì „í˜• êµ¬ë¶„ì´ ëª…í™•í•˜ì§€ ì•ŠìŒ
                                    'recruitment_count': recruitment_count,
                                    'applicant_count': applicant_count
                                })
                                
                            except (ValueError, IndexError) as e:
                                print(f"íŒŒì‹± ì˜¤ë¥˜: {e}")
        
        return competition_data
    
    def clean_department_name(self, department: str, university_code: str) -> str:
        """ëŒ€í•™êµë³„ í•™ê³¼ëª… ì •ë¦¬"""
        # ê³µí†µ ì •ë¦¬
        clean_dept = re.sub(r'êµì§|RISì‚¬ì—…|\s+', ' ', department).strip()
        clean_dept = clean_dept.replace('[ë‹¨ê³¼ëŒ€í•™í†µí•©ëª¨ì§‘]', '')
        
        if university_code == 'CKU':  # ëŒ€êµ¬ê°€í†¨ë¦­ëŒ€í•™êµ
            if 'ì»´í“¨í„°ì†Œí”„íŠ¸ì›¨ì–´' in clean_dept:
                return 'ì»´í“¨í„°ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€'
            elif 'AIë¹…ë°ì´í„°ê³µí•™' in clean_dept:
                return 'AIë¹…ë°ì´í„°ê³µí•™ê³¼'
            elif 'ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©' in clean_dept:
                return 'ì†Œí”„íŠ¸ì›¨ì–´ìœµí•©í•™ê³¼'
        elif university_code == 'DGU':  # ëŒ€êµ¬ëŒ€í•™êµ
            if 'ì»´í“¨í„°ê³µí•™ì „ê³µ' in clean_dept:
                return 'ì»´í“¨í„°ì •ë³´ê³µí•™ë¶€(ì»´í“¨í„°ê³µí•™ì „ê³µ)'
            elif 'ì»´í“¨í„°ì†Œí”„íŠ¸ì›¨ì–´ì „ê³µ' in clean_dept:
                return 'ì»´í“¨í„°ì •ë³´ê³µí•™ë¶€(ì»´í“¨í„°ì†Œí”„íŠ¸ì›¨ì–´ì „ê³µ)'
            elif 'ì‚¬ì´ë²„ë³´ì•ˆì „ê³µ' in clean_dept:
                return 'ì»´í“¨í„°ì •ë³´ê³µí•™ë¶€(ì‚¬ì´ë²„ë³´ì•ˆì „ê³µ)'
            elif 'ì»´í“¨í„°ì •ë³´ê³µí•™' in clean_dept:
                return 'ì»´í“¨í„°ì •ë³´ê³µí•™ë¶€'
        elif university_code == 'KMU':  # ê³„ëª…ëŒ€í•™êµ
            if 'ì»´í“¨í„°ê³µí•™' in clean_dept:
                return 'ì»´í“¨í„°ê³µí•™ê³¼'
            elif 'ê²Œì„ì†Œí”„íŠ¸ì›¨ì–´' in clean_dept:
                return 'ê²Œì„ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼'
            elif 'ëª¨ë¹Œë¦¬í‹°ì†Œí”„íŠ¸ì›¨ì–´' in clean_dept:
                return 'ëª¨ë¹Œë¦¬í‹°ì†Œí”„íŠ¸ì›¨ì–´í•™ê³¼'
        
        return clean_dept.strip()
    
    def extract_number(self, text: str) -> int:
        """í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        numbers = re.findall(r'\d+', text.replace(',', ''))
        return int(numbers[0]) if numbers else 0
    
    def get_or_create_ids(self, university_code: str, college_name: str, 
                         department_name: str, admission_type: str) -> Tuple[int, int, int, int]:
        """ëŒ€í•™êµ, ë‹¨ê³¼ëŒ€í•™, í•™ê³¼, ì „í˜• IDë¥¼ ì¡°íšŒí•˜ê±°ë‚˜ ìƒì„±í•©ë‹ˆë‹¤."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ëŒ€í•™êµ ID ì¡°íšŒ
        cursor.execute('SELECT id FROM universities WHERE code = ?', (university_code,))
        result = cursor.fetchone()
        university_id = result[0] if result else None
        
        if not university_id:
            print(f"ëŒ€í•™êµ ì½”ë“œ '{university_code}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            conn.close()
            return None, None, None, None
        
        # ë‹¨ê³¼ëŒ€í•™ ID ì¡°íšŒ ë˜ëŠ” ìƒì„±
        cursor.execute('SELECT id FROM colleges WHERE university_id = ? AND name = ?', 
                      (university_id, college_name))
        result = cursor.fetchone()
        
        if result:
            college_id = result[0]
        else:
            cursor.execute('INSERT INTO colleges (university_id, name) VALUES (?, ?)', 
                          (university_id, college_name))
            college_id = cursor.lastrowid
        
        # í•™ê³¼ ID ì¡°íšŒ ë˜ëŠ” ìƒì„±
        cursor.execute('SELECT id FROM departments WHERE college_id = ? AND name = ?', 
                      (college_id, department_name))
        result = cursor.fetchone()
        
        if result:
            department_id = result[0]
        else:
            cursor.execute('INSERT INTO departments (college_id, name, target_department) VALUES (?, ?, TRUE)', 
                          (college_id, department_name))
            department_id = cursor.lastrowid
        
        # ì „í˜• ID ì¡°íšŒ ë˜ëŠ” ìƒì„±
        cursor.execute('SELECT id FROM admission_types WHERE name = ?', (admission_type,))
        result = cursor.fetchone()
        
        if result:
            admission_type_id = result[0]
        else:
            cursor.execute('INSERT INTO admission_types (name, category) VALUES (?, ?)', 
                          (admission_type, 'ë¯¸ë¶„ë¥˜'))
            admission_type_id = cursor.lastrowid
        
        conn.commit()
        conn.close()
        
        return university_id, college_id, department_id, admission_type_id
    
    def save_competition_data(self, competition_data: List[Dict], session_id: str):
        """ê²½ìŸë¥  ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        saved_count = 0
        
        for data in competition_data:
            ids = self.get_or_create_ids(
                data['university_code'],
                data['college'],
                data['department'],
                data['admission_type']
            )
            
            if any(id is None for id in ids):
                continue
            
            university_id, college_id, department_id, admission_type_id = ids
            
            try:
                cursor.execute('''
                    INSERT INTO competition_snapshots 
                    (university_id, college_id, department_id, admission_type_id,
                     recruitment_count, applicant_count, crawl_session_id)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (
                    university_id, college_id, department_id, admission_type_id,
                    data['recruitment_count'], data['applicant_count'], session_id
                ))
                saved_count += 1
                
            except sqlite3.Error as e:
                print(f"ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {e}")
        
        conn.commit()
        conn.close()
        
        return saved_count
    
    def update_session_status(self, session_id: str, status: str, error_message: str = None, records_collected: int = 0):
        """í¬ë¡¤ë§ ì„¸ì…˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE crawl_sessions 
            SET end_time = CURRENT_TIMESTAMP, status = ?, 
                error_message = ?, records_collected = ?
            WHERE id = ?
        ''', (status, error_message, records_collected, session_id))
        
        conn.commit()
        conn.close()
    
    def crawl_university(self, university_code: str) -> bool:
        """íŠ¹ì • ëŒ€í•™êµì˜ ê²½ìŸë¥  ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤."""
        config = self.university_configs.get(university_code)
        if not config:
            print(f"ëŒ€í•™êµ ì½”ë“œ '{university_code}' ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        session_id = str(uuid.uuid4())
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT id FROM universities WHERE code = ?', (university_code,))
        result = cursor.fetchone()
        university_id = result[0] if result else None
        
        if not university_id:
            print(f"ëŒ€í•™êµ ì½”ë“œ '{university_code}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            conn.close()
            return False
        
        cursor.execute('INSERT INTO crawl_sessions (id, university_id, status) VALUES (?, ?, ?)', 
                      (session_id, university_id, 'RUNNING'))
        conn.commit()
        conn.close()
        
        try:
            print(f"\n=== {config['name']} í¬ë¡¤ë§ ì‹œì‘ ===")
            
            html_content = self.fetch_page(config['url'])
            if not html_content:
                self.update_session_status(session_id, 'FAILED', 'ì›¹í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨')
                return False
            
            parser = config['parser']
            competition_data = parser(html_content, university_code)
            
            if not competition_data:
                self.update_session_status(session_id, 'COMPLETED', 'ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ')
                print(f"{config['name']}: ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return True
            
            saved_count = self.save_competition_data(competition_data, session_id)
            self.update_session_status(session_id, 'COMPLETED', records_collected=saved_count)
            
            print(f"{config['name']}: {saved_count}ê°œ ë ˆì½”ë“œ ì €ì¥ ì™„ë£Œ")
            return True
            
        except Exception as e:
            self.update_session_status(session_id, 'FAILED', str(e))
            print(f"{config['name']} í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def crawl_all_universities(self):
        """ëª¨ë“  ëŒ€í•™êµì˜ ê²½ìŸë¥  ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤."""
        print("=== ìˆ˜ì •ëœ ë‹¤ì¤‘ ëŒ€í•™êµ ê²½ìŸë¥  í¬ë¡¤ë§ ì‹œì‘ ===")
        start_time = datetime.now()
        
        results = {}
        for university_code in self.university_configs.keys():
            results[university_code] = self.crawl_university(university_code)
            time.sleep(2)  # ìš”ì²­ ê°„ ê°„ê²©
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        print("\n=== í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½ ===")
        for university_code, success in results.items():
            univ_name = self.university_configs[university_code]['name']
            status = "âœ… ì„±ê³µ" if success else "âŒ ì‹¤íŒ¨"
            print(f"{university_code} ({univ_name}): {status}")
        
        print(f"ì´ ì†Œìš” ì‹œê°„: {duration:.1f}ì´ˆ")
        print("=== í¬ë¡¤ë§ ì™„ë£Œ ===")

if __name__ == "__main__":
    from enhanced_database_setup import create_enhanced_database, initialize_base_data, setup_target_departments
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    print("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
    create_enhanced_database()
    initialize_base_data()
    setup_target_departments()
    
    # í¬ë¡¤ë§ ì‹¤í–‰
    crawler = CorrectedMultiUniversityCrawler()
    crawler.crawl_all_universities()